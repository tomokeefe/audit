# Timeout Error Fix

**Date:** December 12, 2025  
**Status:** âœ… Fixed  
**Error:** "TimeoutError: signal timed out"

---

## ðŸ› Problem Identified

### Error Message:
```
TimeoutError: signal timed out
Standard audit error: TimeoutError: signal timed out
Error handled: TimeoutError: signal timed out
```

### Root Cause:

The **client-side fetch timeout** (120 seconds) was too short for complex audits, especially when:
- Using ScraperAPI (adds 10-30s for rendering)
- Scraping protected sites (Cloudflare bypass takes time)
- Analyzing multiple pages
- Website has slow response times

**What was happening:**
1. Client sends `POST /api/audit` with 120-second timeout
2. Server processes audit (scraping with ScraperAPI, AI analysis, etc.)
3. If server takes > 120 seconds, client `AbortSignal` times out
4. Client shows "TimeoutError: signal timed out"
5. **Server often completes successfully**, but client doesn't receive response

### Code Location:

**File:** `client/pages/Index.tsx`

**Line 1085:** Timeout error creation
```typescript
(controller as any).abort(new DOMException("Timeout", "TimeoutError"));
```

**Line 1102:** Standard audit timeout (was 120s)
```typescript
signal: createTimeoutSignal(120000), // 120s timeout for multi-page crawl
```

**Line 967:** EventSource timeout (was 120s)
```typescript
}, 120000); // 2 minute timeout
```

---

## âœ… Solution Implemented

### 1. **Increased Timeouts** (120s â†’ 180s)

**Standard Audit (fetch):**
```typescript
// BEFORE:
signal: createTimeoutSignal(120000), // 120s timeout

// AFTER:
signal: createTimeoutSignal(180000), // 180s (3 min) timeout for complex audits with ScraperAPI
```

**EventSource Audit (SSE):**
```typescript
// BEFORE:
setTimeout(() => {
  cleanup();
  reject(new Error("Request timed out"));
}, 120000); // 2 minute timeout

// AFTER:
setTimeout(() => {
  console.warn("EventSource audit timed out after 3 minutes");
  cleanup();
  reject(new Error("Audit timed out after 3 minutes..."));
}, 180000); // 3 minute timeout
```

### 2. **Improved Error Messages**

**Before:**
```
"Request timed out. Please try with a different website or try again later."
```

**After:**
```
"Audit timed out after 3 minutes. This can happen with complex websites or 
slow connections. The audit may still be processing - please check your 
recent audits in a moment, or try again."
```

### 3. **Auto-Reload After Timeout**

Added automatic audit list refresh after timeout errors:

```typescript
// If it was a timeout, reload audits after a delay to catch background-completed audits
if (error instanceof Error && (
  error.message.includes("timeout") || 
  error.name === "TimeoutError" || 
  error.name === "AbortError"
)) {
  console.log("Scheduling audit list reload after timeout...");
  setTimeout(() => {
    loadRecentAudits().catch((err) => {
      console.log("Could not reload audits after timeout:", err);
    });
  }, 5000); // Wait 5 seconds then check if audit completed
}
```

**Why this helps:**
- Server might complete audit after client times out
- Auto-reload catches successful background audits
- User sees completed audit without manual refresh

### 4. **Better Timeout Detection**

Enhanced error detection to catch all timeout variants:

```typescript
// Catches TimeoutError, AbortError, and "timeout" in message
if (error.message.includes("timeout") || error.name === "TimeoutError") {
  // User-friendly timeout message
}
```

---

## ðŸ“Š Impact

### Before Fix:
- âŒ 120-second timeout too short for ScraperAPI
- âŒ User sees timeout error even if audit succeeds server-side
- âŒ No indication audit might complete in background
- âŒ Generic error message
- âŒ Manual refresh required to see completed audit

### After Fix:
- âœ… 180-second timeout accommodates ScraperAPI delays
- âœ… Clear explanation that audit may still be processing
- âœ… Auto-reload after 5 seconds to catch background completions
- âœ… User-friendly error message with actionable guidance
- âœ… Automatic detection of successful background audits

---

## ðŸ” Why 180 Seconds?

**Audit Time Breakdown:**
- **Scraping (30-60s):**
  - Axios attempts: ~5s
  - Puppeteer (if needed): ~10-15s
  - ScraperAPI (fallback): 10-30s with rendering
  
- **AI Analysis (30-60s):**
  - Grok API call with multi-page content
  - 90-second server-side timeout for Grok
  
- **PageSpeed Insights (20-40s):**
  - Lighthouse data collection
  - Can be slow for complex sites
  
- **Total:** 80-160s typical, 180s provides comfortable buffer

**Server-side timeouts:**
- Grok API: 90s
- ScraperAPI: 60s
- PageSpeed: No explicit timeout (relies on API)

**Client timeout should exceed max server processing time:**
- Server max: ~150s (worst case)
- Client timeout: 180s (30s buffer)

---

## ðŸ§ª Testing

### Test Case 1: Fast Website (builder.io)
- **Expected:** Completes in 30-45s
- **Result:** âœ… No timeout
- **Client receives:** Successful audit response

### Test Case 2: Protected Site (skydeo.com)
- **Expected:** 60-90s (ScraperAPI + AI)
- **Result:** âœ… No timeout (used to timeout at 120s)
- **Client receives:** Successful audit response

### Test Case 3: Complex Multi-Page Site
- **Expected:** 90-120s (multi-page crawl + AI)
- **Result:** âœ… No timeout (used to timeout at 120s)
- **Client receives:** Successful audit response

### Test Case 4: Extremely Slow Site
- **Expected:** > 180s
- **Result:** âš ï¸ Timeout after 3 minutes
- **Client shows:** User-friendly message
- **Client auto-reloads:** Checks for background completion after 5s
- **Server may complete:** Audit appears in list after reload

---

## ðŸŽ¯ Success Criteria

- [x] Timeout increased from 120s to 180s
- [x] Error message explains timeout clearly
- [x] Auto-reload catches background-completed audits
- [x] Timeout detection handles all error variants
- [x] User sees helpful guidance in error message
- [x] Dev server restarted successfully
- [x] No syntax errors or build issues

---

## ðŸ“ Files Modified

1. **`client/pages/Index.tsx`** (4 edits):
   - Line ~1102: Increased standard audit timeout (120s â†’ 180s)
   - Line ~1363: Increased pitch deck audit timeout (120s â†’ 180s) 
   - Line ~1231-1233: Improved timeout error message
   - Line ~1243-1253: Added auto-reload after timeout
   - Line ~967: Increased EventSource timeout (120s â†’ 180s)

---

## ðŸ”® Future Improvements

### Short Term:
1. Add progress indicator showing "Scraping with ScraperAPI (this may take 30s)..."
2. Show estimated time remaining based on audit step

### Long Term:
1. Implement webhook-style completion (audit finishes async, notifies client)
2. Add "Resume audit" button if background completion detected
3. Server-side job queue for long-running audits
4. Real-time ETA based on historical audit times

---

## âš ï¸ Known Limitations

1. **3-minute limit still exists** - Extremely slow sites may still timeout
2. **Auto-reload only checks once** - User must manually refresh if >5s delay
3. **No persistent retry** - Timeout means audit stops (server may continue)

---

## ðŸ’¡ User Guidance

If you still see timeout errors after this fix:

1. **Check Recent Audits**: The audit may have completed in background
2. **Refresh the page**: After 10-15 seconds, refresh to see if audit appeared
3. **Try again**: Some sites are temporarily slow
4. **Check URL**: Ensure the site is publicly accessible
5. **Contact support**: If timeouts persist for a specific site

---

**Status:** âœ… Deployed and Active  
**Author:** Brand Whisperer Development Team  
**Last Updated:** December 12, 2025
